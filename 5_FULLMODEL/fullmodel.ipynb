{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200fc037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from copy import copy\n",
      "from scipy import stats\n",
      "from sklearn import metrics,neighbors,preprocessing\n",
      "from sklearn import tree\n",
      "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
      "from sklearn.ensemble import IsolationForest\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "from sklearn.linear_model import LinearRegression, Ridge\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import LogisticRegression as LR\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import cohen_kappa_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import mean_squared_error as mse\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import r2_score,mean_squared_error\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import recall_score, accuracy_score, precision_score,f1_score, make_scorer\n",
      "from sklearn.metrics import recall_score, accuracy_score, precision_score,f1_score, make_scorer \n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "from sklearn.model_selection import cross_val_score as cv\n",
      "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict, LeaveOneOut, KFold, StratifiedKFold\n",
      "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut,GridSearchCV,RandomizedSearchCV\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
      "from sklearn.pipeline import make_pipeline, make_union\n",
      "from sklearn.preprocessing import FunctionTransformer\n",
      "from sklearn.svm import SVC\n",
      "from time import time\n",
      "from xgboost import XGBClassifier, XGBRegressor, plot_tree, plot_importance\n",
      "from xgboost import XGBClassifier, plot_tree, plot_importance\n",
      "import copy\n",
      "import csv,sys, os, errno,os.path,io\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import multiprocessing\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy\n",
      "import seaborn as sns\n",
      "import tqdm\n",
      "import xgboost as xgb\n"
     ]
    }
   ],
   "source": [
    "from MLimports2 import *\n",
    "exec(MLimports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f365e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tpot import TPOTClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# iris = load_iris()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(iris.data.astype(np.float64),\n",
    "#     iris.target.astype(np.float64), train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85e1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Predict the class of the incident (using optimal threshold)\n",
    "# 2. Gather data on either short or long-term incidents to train regression model\n",
    "# 3. Use cross-validation, where this performed for each fold.\n",
    "# (but find optimal models first - 1) to predict class 2) to predict duration within class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c54e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find the best model (hyper-parameters) for classification\n",
    "# 2. Find the best models (hyper-parameters) for regression of short term incidents and long-term incidents\n",
    "# 3. Find the best overall model\n",
    "\n",
    "# 10-fold cross-validation\n",
    "#     1. Train on train-set and perform classification (divide incidents into two groups)\n",
    "#     2. Use best model hyper-parameters to train regression model A-A, use samples based on the predicted duration\n",
    "#     3. Use best model hyper-parameters to train regression model B-B, use samples based on the predicted duration\n",
    "#     4. Collect predictions and estimate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde4d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 10% as the test set\n",
    "# 80% train and 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da66634",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpotcla_config = {    \n",
    "    \n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'dual': [True, False]\n",
    "    },\n",
    "    \n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf':  range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 10),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "    },\n",
    "        'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 10),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0]\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "tpotreg_config = {    \n",
    "\n",
    "    'sklearn.ensemble.GradientBoostingRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 10),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'alpha': [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "    },\n",
    "    \n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.RidgeCV': {\n",
    "    },\n",
    "\n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 10),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0],\n",
    "        'objective': ['reg:squarederror']\n",
    "    },\n",
    "}\n",
    "\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4b84d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/480 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.9321262121765944\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.9321262121765944\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.9302253442844158\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.9302253442844158\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.9302253442844158\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, bootstrap=True, max_features=0.2, min_samples_leaf=7, min_samples_split=7, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[2,-1],dataset='m')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10,template='Regressor',population_size=80, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestfullreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63701c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/480 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.47396751895249284\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.4738674033383584\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.47145890692244413\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.47145890692244413\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.47020932464956644\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.99, learning_rate=0.1, loss=huber, max_depth=2, max_features=0.9000000000000001, min_samples_leaf=17, min_samples_split=2, n_estimators=100, subsample=1.0)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[2,45],dataset='m')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10, template='Regressor',population_size=80, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestAreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21f82fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/480 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.266778491973949\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.2660774156941762\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.2660774156941762\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.26565909575672053\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.26565909575672053\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, bootstrap=True, max_features=0.15000000000000002, min_samples_leaf=3, min_samples_split=9, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[45,-1],dataset='m')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10, template='Regressor',population_size=80, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestBreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a17d79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/600 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.48959490677407064\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.49069298005032047\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.49069298005032047\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.49069298005032047\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.49069298005032047\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=1.0, max_depth=1, min_child_weight=19, n_estimators=100, n_jobs=1, subsample=0.3, verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "X,Y = getBFS(part=[2,-1],dataset='m')\n",
    "X = X.values\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=45).ravel()\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, cv=10, scoring='f1', template='Classifier',population_size=100, verbosity=2, n_jobs=30,random_state=42,config_dict=tpotcla_config)\n",
    "tpot.fit(X,Ybin)\n",
    "# print(tpot.score(X,Ybin))\n",
    "bestfullcla = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae1b3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEfull,RMSEreg,MAPEfull,MAPEreg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.0,71.0,205.0,143.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0,68.0,180.0,114.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.0,65.0,204.0,126.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.0,68.0,250.0,139.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0,72.0,197.0,128.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.0,61.0,203.0,124.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.0,76.0,226.0,128.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.0,66.0,195.0,117.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.0,74.0,206.0,132.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0,65.0,202.0,120.0\n",
      "RMSEfull,RMSEreg,MAPEfull,MAPEreg\n",
      "77.0,71.0,205.0,143.0\n",
      "71.0,68.0,180.0,114.0\n",
      "66.0,65.0,204.0,126.0\n",
      "73.0,68.0,250.0,139.0\n",
      "75.0,72.0,197.0,128.0\n",
      "65.0,61.0,203.0,124.0\n",
      "79.0,76.0,226.0,128.0\n",
      "72.0,66.0,195.0,117.0\n",
      "78.0,74.0,206.0,132.0\n",
      "67.0,65.0,202.0,120.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "X,Y = getBFS(part=[2,-1],dataset='m')\n",
    "X = X.values\n",
    "\n",
    "# def quantilefold(X,Y):\n",
    "#     zipped = list(zip(X,Y))\n",
    "#     X = [A for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     Y = [B for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     X = np.array(X)\n",
    "#     Y = np.array(Y)\n",
    "#     return X,Y\n",
    "\n",
    "# X,Y = quantilefold(X,Y)\n",
    "\n",
    "\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=45).ravel()\n",
    "Yfull = np.concatenate([Y.reshape(-1,1),Ybin.reshape(-1,1)],axis=1)\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "kf.get_n_splits(X,Yfull)\n",
    "\n",
    "print(\"RMSEfull,RMSEreg,MAPEfull,MAPEreg\")\n",
    "\n",
    "RES=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X,Yfull):\n",
    "    \n",
    "    # reset models (since some may use iterative training)\n",
    "#     bestAreg.fit([[0],[0]],[0,0])\n",
    "#     bestBreg.fit([[0],[0]],[0,0])\n",
    "#     bestfullreg.fit([[0],[0]],[0,0])\n",
    "#     bestfullcla.fit([[0],[0]],[0,1])\n",
    "#     print()\n",
    "    \n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Yfull[train_index], Yfull[test_index]\n",
    "    \n",
    "    # one regression model predictions\n",
    "    reg = bestfullreg\n",
    "    reg.fit(Xtr,np.log1p(Ytr[:,0]))\n",
    "    Rpreds = np.expm1(reg.predict(Xte))\n",
    "    RTrpreds = np.expm1(reg.predict(Xtr))\n",
    "    \n",
    "    #one classification model predictions\n",
    "    cla = bestfullcla\n",
    "    cla.fit(Xtr,Ytr[:,1])\n",
    "    Cpreds = cla.predict(Xte)\n",
    "    CTrpreds = cla.predict(Xtr)\n",
    "    \n",
    "    \n",
    "    # A- and B- models try to predict\n",
    "    regA = bestAreg\n",
    "    regB = bestBreg\n",
    "    \n",
    "    As = Ytr[:,1]==0\n",
    "    Bs = Ytr[:,1]==1\n",
    "    regA.fit(Xtr[As],np.log1p(Ytr[As,0]))\n",
    "    regB.fit(Xtr[Bs],np.log1p(Ytr[Bs,0]))\n",
    "    \n",
    "    Apreds = np.expm1(regA.predict(Xte))\n",
    "    Bpreds = np.expm1(regB.predict(Xte))\n",
    "    \n",
    "    ATrpreds = np.expm1(regA.predict(Xtr))\n",
    "    BTrpreds = np.expm1(regB.predict(Xtr))\n",
    "    #accumulating predictions\n",
    "    \n",
    "    R3tr = np.concatenate([reg.predict(Xtr).reshape(-1,1), regA.predict(Xtr).reshape(-1,1), regB.predict(Xtr).reshape(-1,1), cla.predict(Xtr).reshape(-1,1)],axis=1)\n",
    "    R3te = np.concatenate([reg.predict(Xte).reshape(-1,1), regA.predict(Xte).reshape(-1,1), regB.predict(Xte).reshape(-1,1), cla.predict(Xte).reshape(-1,1)],axis=1)\n",
    "#     print(R3tr.shape,Ytr[:,0].shape)\n",
    "\n",
    "    from sklearn.linear_model import RidgeCV\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "    full = XGBRegressor()#DTR(max_depth=4)\n",
    "#     full = TPOTRegressor(generations=5, template='Regressor',population_size=40, verbosity=2, n_jobs=20,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "    full.fit(R3tr,np.log1p(Ytr[:,0]))\n",
    "#     bestfullreg.fit([[0],[0]],[0,0])\n",
    "#     finalreg = bestfullreg\n",
    "#     finalreg.fit(R3tr,Ytr[:,0])\n",
    "    \n",
    "    \n",
    "    PREDS = np.expm1(full.predict(R3te))\n",
    "    \n",
    "    \n",
    "    \n",
    "    TRPREDS = []\n",
    "    \n",
    "    for i in range(len(Xtr)):\n",
    "        \n",
    "        if CTrpreds[i]==0:\n",
    "            TRPREDS.append(ATrpreds[i])\n",
    "            \n",
    "        if CTrpreds[i]==1:\n",
    "            TRPREDS.append(BTrpreds[i])\n",
    "            \n",
    "    TEPREDS = []\n",
    "    \n",
    "    for i in range(len(Xte)):\n",
    "        \n",
    "        if Cpreds[i]==0:\n",
    "            TEPREDS.append(Apreds[i])\n",
    "            \n",
    "        if Cpreds[i]==1:\n",
    "            TEPREDS.append(Bpreds[i])  \n",
    "    TRPREDS = np.array(TRPREDS).reshape(-1,1)  \n",
    "    \n",
    "#     print(TRPREDS.shape)\n",
    "    TEPREDS = np.array(TEPREDS).reshape(-1,1)\n",
    "#     print(TEPREDS.shape)\n",
    "    \n",
    "    full.fit(np.concatenate([TRPREDS,CTrpreds.reshape(-1,1),ATrpreds.reshape(-1,1),BTrpreds.reshape(-1,1)],axis=1), np.log1p(Ytr[:,0]))\n",
    "    PREDS = full.predict(np.concatenate([TEPREDS,Cpreds.reshape(-1,1),Apreds.reshape(-1,1),Bpreds.reshape(-1,1)],axis=1))\n",
    "    PREDS = np.expm1(PREDS)\n",
    "    PREDS=TEPREDS\n",
    "    \n",
    "    rA, rB = np.sqrt(mse(Yte[:,0],np.array(PREDS))), np.sqrt(mse(Yte[:,0],np.array(Rpreds)))\n",
    "    mA, mB = mape(Yte[:,0],np.array(PREDS)), mape(Yte[:,0],np.array(Rpreds))\n",
    "    rA = np.round(rA)\n",
    "    rB = np.round(rB)\n",
    "    mA = np.round(mA)\n",
    "    mB = np.round(mB)\n",
    "    print(\"{},{},{},{}\".format(rA, rB, mA, mB))\n",
    "    RES.append(\"{},{},{},{}\".format(rA, rB, mA, mB))\n",
    "#     print(PREDS[0],Rpreds[0])\n",
    "\n",
    "\n",
    "print(\"RMSEfull,RMSEreg,MAPEfull,MAPEreg\")\n",
    "print(\"\\n\".join(RES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6456363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "868a2cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a95b9929852c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'regA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'regB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cla'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mplot_tree\u001b[0;34m(decision_tree, max_depth, feature_names, class_names, label, filled, impurity, node_ids, proportion, rotate, rounded, precision, ax, fontsize)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \"\"\"\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrotate\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This XGBRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "plot_tree(full,max_depth=2,feature_names=['reg','regA','regB','cla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0031ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc637025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [120   1]\n",
      " [ 90   1]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [ 60   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 75   1]\n",
      " [380   1]\n",
      " [ 90   1]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [ 45   1]\n",
      " [ 90   1]\n",
      " [ 75   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [353   1]\n",
      " [ 60   1]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 60   1]\n",
      " [ 47   1]\n",
      " [ 75   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 75   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [414   1]\n",
      " [ 90   1]\n",
      " [ 90   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 30   0]\n",
      " [ 45   1]\n",
      " [ 45   1]\n",
      " [ 45   1]\n",
      " [ 45   1]\n",
      " [ 30   0]\n",
      " [ 46   1]\n",
      " [ 90   1]\n",
      " [ 30   0]]\n"
     ]
    }
   ],
   "source": [
    "print(full[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "80ba7aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = getBFS(part=[39,-1],dataset='sf')\n",
    "Y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2eb10dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "        True,  True, False, False,  True, False,  True, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "        True,  True, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "       False, False,  True,  True, False,  True, False,  True, False,\n",
       "        True, False, False, False, False,  True, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False,  True,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "        True,  True, False,  True,  True, False, False, False,  True,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True,  True, False, False,\n",
       "       False,  True,  True, False,  True, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "       False, False, False,  True,  True, False,  True,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "       False,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True, False,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "        True, False,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True, False,  True, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919bba04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b9f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81498f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d739deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7d9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb087d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "             max_depth=1, min_child_weight=3, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=200, n_jobs=1,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=0.6000000000000001, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "977251e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbase,Xte,Ybase,Yte = train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec521e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xva,Ytr,Yva = train_test_split(Xbase,Ybase,test_size=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b28f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1650a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -3087.5178072693934\n",
      "\n",
      "Generation 2 - Current best internal CV score: -3087.5178072693934\n",
      "\n",
      "Generation 3 - Current best internal CV score: -3011.0816757393454\n",
      "\n",
      "Generation 4 - Current best internal CV score: -2968.3305589359\n",
      "\n",
      "Generation 5 - Current best internal CV score: -2968.3305589359\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.75, learning_rate=0.1, loss=ls, max_depth=2, max_features=0.9000000000000001, min_samples_leaf=6, min_samples_split=5, n_estimators=100, subsample=0.5)\n",
      "-1653.2819865987983\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "034a06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfullreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57156c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d803299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954aef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c906030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e37b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02e373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c12ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9cca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca4ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bdbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bfbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f2e2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(X,Y))\n",
    "X = [A for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "Y = [B for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12bc2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66.41859826165862, 45.843493276510266]\n"
     ]
    }
   ],
   "source": [
    "#QUANTILED\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RES=[]\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=False)\n",
    "\n",
    "kf.get_n_splits(X,Y)\n",
    "RMSEQ = []\n",
    "\n",
    "for train_index, test_index in kf.split(X,Y):\n",
    "#             print('k')\n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Y[train_index], Y[test_index]\n",
    "    #reg = QuantileRegressor(quantile=quantile, alpha=0)\n",
    "    reg = XGBRegressor(n_estimators=150,verbosity = 0)\n",
    "    reg.fit(Xtr,Ytr)\n",
    "    preds = reg.predict(Xte)\n",
    "    RMSEQ.append(np.sqrt(mse(Yte,preds)))\n",
    "#     RMSEQ.append(mape(Yte,preds))\n",
    "            \n",
    "RES.append([np.mean(RMSEQ),np.std(RMSEQ)])\n",
    "print(RES[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a53f9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES=[]\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X,Y)\n",
    "RMSEQ = []\n",
    "\n",
    "for train_index, test_index in kf.split(X,Y):\n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Y[train_index], Y[test_index]\n",
    "    reg = XGBRegressor(n_estimators=350,verbosity = 0)\n",
    "    reg.fit(Xtr,Ytr)\n",
    "    preds = reg.predict(Xte)\n",
    "    RMSEQ.append(np.sqrt(mse(Yte,preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e0fb65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58.033465914479855,\n",
       " 35.272086804733945,\n",
       " 45.15763871358063,\n",
       " 81.12830161070828,\n",
       " 57.677462708625455,\n",
       " 92.02634839463795,\n",
       " 94.27136734291784,\n",
       " 70.39178288106343,\n",
       " 98.14809337183857,\n",
       " 76.2484835862898]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "615da013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('axes', axisbelow=True)\n",
    "plt.figure(figsize=(4,3.5))\n",
    "plt.bar(np.array(list(range(len(RMSEQ)))),RMSEQ)\n",
    "plt.xlabel('Fold',fontsize=13)\n",
    "plt.ylabel('MAPE [%]',fontsize=13)\n",
    "plt.xticks(np.arange(0,10))\n",
    "plt.text(-0.4, max(RMSEQ)*0.93, 'a)', fontsize = 20)\n",
    "plt.grid()\n",
    "# plt.ylim(0,90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('A_KF.pdf')\n",
    "# plt.title('10 quantiled time-folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de166d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d97630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afb27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d00844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fb15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0f602b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 29.0, 29.0, 30.0, 44.0, 47.0, 72.0, 108.0, 360.0, 2715.0]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.quantile(Y,A) for A in np.linspace(0.0,1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ab4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ddf05e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.95608084175136, 7.333926505347353]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "RES=[]\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "kf.get_n_splits(X,Y)\n",
    "RMSE = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X,Y):\n",
    "#             print('k')\n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Y[train_index], Y[test_index]\n",
    "    #reg = QuantileRegressor(quantile=quantile, alpha=0)\n",
    "#     for i in range(10):\n",
    "    reg = XGBRegressor(n_estimators=100,verbosity = 0)\n",
    "    reg.fit(Xtr,Ytr)\n",
    "    preds = reg.predict(Xte)\n",
    "    RMSE.append(np.sqrt(mse(Yte,preds)))\n",
    "            \n",
    "RES.append([np.mean(RMSE),np.std(RMSE)])\n",
    "print(RES[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d32ecaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.40480450880131,\n",
       " 51.73428926895006,\n",
       " 47.030082339087336,\n",
       " 50.65605126405232,\n",
       " 42.50628689118303,\n",
       " 43.62171836222986,\n",
       " 46.24212844494563,\n",
       " 50.87276134896721,\n",
       " 70.16020917363426,\n",
       " 47.33247681566265]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24a0b342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '10-folds')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(range(len(RMSE))),RMSE)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('10-folds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac073fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9687a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "434b5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = QuantileRegressor(quantile=0.5,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49e30e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\python39\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:268: ConvergenceWarning: Linear programming for QuantileRegressor did not succeed.\n",
      "Status is 1: Iteration limit reached.\n",
      "Result message of linprog:\n",
      "The iteration limit was reached before the algorithm converged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantileRegressor(alpha=0.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
