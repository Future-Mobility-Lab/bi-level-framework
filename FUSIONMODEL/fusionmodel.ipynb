{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "200fc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLimports2 import *\n",
    "exec(MLimports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c54e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find the best model (hyper-parameters) for classification\n",
    "# 2. Find the best models (hyper-parameters) for regression of short term incidents and long-term incidents\n",
    "# 3. Find the best All-to-All regression model\n",
    "\n",
    "# 10-fold cross-validation\n",
    "#     1. Train on train-set and perform classification (divide incidents into two groups)\n",
    "#     2. Use best model hyper-parameters to train regression model A-A, use samples based on the predicted duration\n",
    "#     3. Use best model hyper-parameters to train regression model B-B, use samples based on the predicted duration\n",
    "#     4. Collect predictions and estimate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b954c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yt,yp):\n",
    "    return mean_squared_error(yt,yp)\n",
    "\n",
    "def rmse(yt,yp):\n",
    "    return np.sqrt(mean_squared_error(yt,yp))\n",
    "\n",
    "\n",
    "METRIC = {'name':'RMSE','instance':rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "34a4153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n"
     ]
    }
   ],
   "source": [
    "#Table 5. Data set SF. All-to-All, A-to-A, B-to-B regression.\n",
    "# best All-to-All model for the data set SF\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV as RCV\n",
    "\n",
    "OPT={'name':'LGBM','instance':lgb.LGBMRegressor,'param':{\n",
    "            'feature_fraction':np.linspace(0.5,1,100),'bagging_fraction':np.linspace(0.5,1,100),\n",
    "            'learning_rate' : np.linspace(0.00001,1,10000), 'lambda_l1':np.linspace(0,5,1000),'lambda_l2':np.linspace(0,5,1000),\n",
    "            'max_depth' : np.arange(2,15), 'metric':['MAE','RMSE'],'objective':['huber', 'gamma', 'fair', 'tweedie'],\n",
    "        }}\n",
    "\n",
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "\n",
    "reg = RCV(OPT['instance'](),OPT['param'],cv=10,n_jobs=20,random_state=1000,n_iter=250)\n",
    "reg.fit(X,np.log1p(Y))\n",
    "bestfullreg = OPT['instance'](**reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ed6838f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regression model for A part\n",
    "X,Y = getBFS(part=[0,45],dataset='sf')\n",
    "\n",
    "reg = RCV(OPT['instance'](),OPT['param'],cv=10,n_jobs=20,random_state=1000,n_iter=250)\n",
    "reg.fit(X,Y)\n",
    "bestAreg = OPT['instance'](**reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2f9d2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regression model for B part\n",
    "X,Y = getBFS(part=[45,-1],dataset='sf')\n",
    "\n",
    "reg = RCV(OPT['instance'](),OPT['param'],cv=10,n_jobs=20,random_state=1000,n_iter=250)\n",
    "reg.fit(X,Y)\n",
    "bestBreg = OPT['instance'](**reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5ecba094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8888888888888888,\n",
       "              feature_fraction=0.7929292929292929,\n",
       "              lambda_l1=0.10010010010010009, lambda_l2=0.2802802802802803,\n",
       "              learning_rate=0.07351661566156616, max_depth=8, metric='MAE',\n",
       "              objective='fair')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestBreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "376713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best classifier\n",
    "OPT = {'name':'RF','instance': RandomForestClassifier, 'param':{\n",
    "    'n_estimators' : np.arange(20,200,1),\n",
    "    'max_depth':np.arange(2,15,1),\n",
    "}}\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "X = X.values\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=45).ravel()\n",
    "\n",
    "\n",
    "cla = RCV(OPT['instance'](),OPT['param'],cv=10,n_jobs=20,random_state=1000,n_iter=250)\n",
    "cla.fit(X,Ybin)\n",
    "\n",
    "bestfullcla = OPT['instance'](**cla.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fcecba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "85.0,87.0,91.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "47.0,83.0,85.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "47.0,50.0,57.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "56.0,63.0,65.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "46.0,63.0,69.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "55.0,71.0,75.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "69.0,71.0,77.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "47.0,50.0,53.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "57.0,115.0,111.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10010010010010009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10010010010010009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8888888888888888, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888888888888888\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7929292929292929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7929292929292929\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2802802802802803, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2802802802802803\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8308308308308309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8308308308308309\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7626262626262627, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7626262626262627\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7878787878787878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7878787878787878\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7777777777777777, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7777777777777777\n",
      "53.0,88.0,81.0\n",
      "RMSEfusion,RMSEreg,RMSEpipe\n",
      "85.0,87.0,91.0\n",
      "47.0,83.0,85.0\n",
      "47.0,50.0,57.0\n",
      "56.0,63.0,65.0\n",
      "46.0,63.0,69.0\n",
      "55.0,71.0,75.0\n",
      "69.0,71.0,77.0\n",
      "47.0,50.0,53.0\n",
      "57.0,115.0,111.0\n",
      "53.0,88.0,81.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import RidgeCV    \n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "X = X.values\n",
    "\n",
    "# def quantilefold(X,Y):\n",
    "#     zipped = list(zip(X,Y))\n",
    "#     X = [A for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     Y = [B for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     X = np.array(X)\n",
    "#     Y = np.array(Y)\n",
    "#     return X,Y\n",
    "\n",
    "# X,Y = quantilefold(X,Y)\n",
    "\n",
    "\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=45).ravel()\n",
    "Yfull = np.concatenate([Y.reshape(-1,1),Ybin.reshape(-1,1)],axis=1)\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "kf.get_n_splits(X,Yfull)\n",
    "\n",
    "RES=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X,Yfull):\n",
    "    \n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Yfull[train_index], Yfull[test_index]\n",
    "    \n",
    "    # one regression model predictions\n",
    "    reg = bestfullreg\n",
    "    reg.fit(Xtr,np.log1p(Ytr[:,0]))\n",
    "    Rpreds = np.expm1(reg.predict(Xte))\n",
    "    RTrpreds = np.expm1(reg.predict(Xtr))\n",
    "    \n",
    "    # classification model predictions\n",
    "    cla = bestfullcla\n",
    "    cla.fit(Xtr,Ytr[:,1])\n",
    "    Cpreds = cla.predict(Xte)\n",
    "    CTrpreds = cla.predict(Xtr)\n",
    "    \n",
    "    # A- and B- models try to predict\n",
    "    regA = bestAreg\n",
    "    regB = bestBreg\n",
    "    \n",
    "    As = Ytr[:,1]==0\n",
    "    Bs = Ytr[:,1]==1\n",
    "    regA.fit(Xtr[As],np.log1p(Ytr[As,0]))\n",
    "    regB.fit(Xtr[Bs],np.log1p(Ytr[Bs,0]))\n",
    "    \n",
    "    Apreds = np.expm1(regA.predict(Xte))\n",
    "    Bpreds = np.expm1(regB.predict(Xte))\n",
    "    \n",
    "    ATrpreds = np.expm1(regA.predict(Xtr))\n",
    "    BTrpreds = np.expm1(regB.predict(Xtr))\n",
    "    # accumulating predictions\n",
    "    \n",
    "    \n",
    "    # performing training on predictions on the training part\n",
    "#     R3tr = np.concatenate([reg.predict(Xtr).reshape(-1,1), regA.predict(Xtr).reshape(-1,1), regB.predict(Xtr).reshape(-1,1), cla.predict(Xtr).reshape(-1,1)],axis=1)\n",
    "#     R3te = np.concatenate([reg.predict(Xte).reshape(-1,1), regA.predict(Xte).reshape(-1,1), regB.predict(Xte).reshape(-1,1), cla.predict(Xte).reshape(-1,1)],axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "#     full.fit(R3tr,np.log1p(Ytr[:,0]))\n",
    "    \n",
    "    # after training the fusion model - making predictions\n",
    "#     PREDS = np.expm1(full.predict(R3te))\n",
    "    \n",
    "#     TRPREDS = []\n",
    "    \n",
    "#     for i in range(len(Xtr)):\n",
    "        \n",
    "#         if CTrpreds[i]==0:\n",
    "#             TRPREDS.append(ATrpreds[i])\n",
    "            \n",
    "#         if CTrpreds[i]==1:\n",
    "#             TRPREDS.append(BTrpreds[i])\n",
    "            \n",
    "    TEPREDS = []\n",
    "    \n",
    "    for i in range(len(Xte)):\n",
    "        \n",
    "        if Cpreds[i]==0:\n",
    "            TEPREDS.append(Apreds[i])\n",
    "            \n",
    "        if Cpreds[i]==1:\n",
    "            TEPREDS.append(Bpreds[i])  \n",
    "    \n",
    "    #pipeline predictions\n",
    "#     TRPREDS = np.array(TRPREDS).reshape(-1,1)  \n",
    "    TEPREDS = np.array(TEPREDS).reshape(-1,1)\n",
    "    \n",
    "    fusion = XGBRegressor()\n",
    "    fusion.fit(np.concatenate([RTrpreds.reshape(-1,1),CTrpreds.reshape(-1,1),ATrpreds.reshape(-1,1),BTrpreds.reshape(-1,1)],axis=1), np.log1p(Ytr[:,0]))\n",
    "    PREDS = fusion.predict(np.concatenate([Rpreds.reshape(-1,1),Cpreds.reshape(-1,1),Apreds.reshape(-1,1),Bpreds.reshape(-1,1)],axis=1))\n",
    "    PREDS = np.expm1(PREDS)\n",
    "#     PREDS=PREDS\n",
    "    \n",
    "    rA, rB = np.sqrt(mse(Yte[:,0],np.array(PREDS))), np.sqrt(mse(Yte[:,0],np.array(Rpreds)))\n",
    "    \n",
    "    rP = np.sqrt(mse(Yte[:,0],np.array(TEPREDS).ravel()))\n",
    "\n",
    "    rA = np.round(rA)\n",
    "    rB = np.round(rB)\n",
    "    rP = np.round(rP)\n",
    "\n",
    "    print(\"{},{},{}\".format(rA, rB, rP))\n",
    "    RES.append(\"{},{},{}\".format(rA, rB, rP))\n",
    "\n",
    "print(\"RMSEfusion,RMSEreg,RMSEpipe\")\n",
    "print(\"\\n\".join(RES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "60586c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('SF_fusion2.csv','w')\n",
    "out.write(\"RMSEfusion,RMSEreg,RMSEpipe\\n\")\n",
    "out.write(\"\\n\".join(RES))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6406ca42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEmCAYAAACOHIIgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwDUlEQVR4nO3deXxU5dn/8c9Fwh4gKBBIRNGqIIsbaF0QghuiFFBxYROEilStWmwtamVxr3XrT1pxB5eCSFsV1Ieqhba0yiNUH0FZRAUCgbAoS0CBwPX7Y4YwCckwCZnMzOH7fr3ycu5zn+XLOMk15z6buTsiIiISLDUSHUBERESqngq8iIhIAKnAi4iIBJAKvIiISACpwIuIiASQCryIiEgAVVuBN7MXzGydmS2MmPY7M1tsZp+Z2V/NLDOi7w4zW2ZmS8yse3XlFBERCYLq3IOfCFxUatp7QHt3PxFYCtwBYGZtgauBduFl/mhmadUXVUREJLWlV9eG3P2fZtaq1LS/RTQ/AvqGX/cGprj7DuAbM1sGnA58GG0bTZo08VatWkWbpdK2bdtG/fr147LueEi1vJB6mVMtLyhzdUi1vKDM1SGeeefPn7/B3ZuWnl5tBT4GQ4HXwq9zCBX8vVaFp0XVqlUr5s2bF4doMHv2bHJzc+Oy7nhItbyQeplTLS8oc3VItbygzNUhnnnNbEWZ06vzVrXhPfgZ7t6+1PS7gE7AZe7uZjYe+MjdXwn3Pw+86+7TyljncGA4QFZWVscpU6bEJXthYSEZGRlxWXc8pFpeSL3MqZYXlLk6pFpeUObqEM+83bp1m+/unfbrcPdq+wFaAQtLTRtCaOi9XsS0O4A7ItozgTMPtP6OHTt6vMyaNStu646HVMvrnnqZUy2vuzJXh1TL667M1SGeeYF5XkZNTOhlcmZ2EXA70Mvdt0d0vQVcbWa1zexo4DjgfxORUUREJBVV2zF4M5sM5AJNzGwVMIbQnnpt4D0zg9Cw/Ah3/9zMpgJfAEXAje6+u7qyioiIpLrqPIu+XxmTn48y//3A/fFLJCIiEly6k52IiEgAqcCLiIgEkAq8iIhIAKnAi4iIBJAKvIiISAAl061qRUREyja2Ucl263Ewtne4b3P150kB2oMXEREJIBV4ERGRAFKBFxERCSAVeBERkQBSgRcREQkgFXgREZEAUoEXEREJIF0HLyIiKa3DpA5R+xcMXlBNSZKL9uBFREQCSAVeREQkgFTgRUREAkgFXkREJIBU4EVERAJIBV5ERCSAVOBFREQCSAVeREQkgFTgRUREAkgFXkREJIBU4EVERAJIBV5ERCSAVOBFREQCSAVeREQkgFTgRUREAkgFXkREJIBU4EVERAJIBV5ERCSAqq3Am9kLZrbOzBZGTDvMzN4zsy/D/20cnm5m9v/MbJmZfWZmp1ZXThERkSCozj34icBFpaaNAj5w9+OAD8JtgB7AceGf4cBT1ZRRREQkEKqtwLv7P4FvS03uDUwKv54E9ImY/pKHfARkmlmLagkqIiISAObu1bcxs1bADHdvH25vcvfM8GsDvnP3TDObATzk7nPCfR8Av3b3eWWsczihvXyysrI6TpkyJS7ZCwsLycjIiMu64yHV8kLqZU61vKDM1SHV8kKKZF7zaYlmYe1sMnbkA/BFrVpRF217eNt4pYpZPN/jbt26zXf3TqWnp8dla5Xg7m5mFf624e7PAM8AdOrUyXNzc6s6GgCzZ88mXuuOh1TLC6mXOdXygjJXh1TLCymSeWzvEs3ZrceRu2QMAD8/+sioiy64fEHcYsUqEe9xos+iL9g79B7+77rw9NVAy4j5jghPExERkRgkusC/BQwOvx4MvBkx/Zrw2fRnAJvdfU0iAoqIiKSiahuiN7PJQC7QxMxWAWOAh4CpZjYMWAFcGZ79HeBiYBmwHbi2unKKiIgEQbUVeHfvV07XeWXM68CN8U0kIiISXIkeohcREZE4UIEXEREJIBV4ERGRAFKBFxERCSAVeBERkQBSgRcREQkgFXgREZEAUoEXEREJIBV4ERGRAFKBFxERCSAVeBERkQBSgRcREQkgFXgREZEAqranyQVJh0kdovYvGLygmpKIiIiUTXvwIiIiAaQCLyIiEkAq8CIiIgGkAi8iIhJAKvAiIiIBpLPoRURE4mFso32vW4+Dsb0j+jbHffPagxcREQkg7cGXJ/KbF5T89nX0kdWfR0REpAK0By8iIhJAKvAiIiIBpAIvIiISQIfsMfhWo96O2r+8TjUFqSbR7p+ve+eLiASP9uBFREQCSAVeREQkgFTgRUREAuiQPQYfONGu2wdduy8icojRHryIiEgAJUWBN7NfmNnnZrbQzCabWR0zO9rM5prZMjN7zcxqJTqniIhIqkh4gTezHOBmoJO7twfSgKuB3wKPu/uxwHfAsMSlFBERSS3Jcgw+HahrZruAesAa4Fygf7h/EjAWeCoh6URERKpQddybJOF78O6+GngEWEmosG8G5gOb3L0oPNsqICcxCUVERFKPuXtiA5g1Bv4MXAVsAl4HpgFjw8PzmFlL4N3wEH7p5YcDwwGysrI6TpkyJabtLlgd/Vm8HWp8U6JdWDubjB35AHxRK/rpAG0PbxtThiq15tMSzci8ED1zQvKWobCwkIyMjETHiFmq5QVlrg6plhdSJHOUv3FJ+TcZSmSO59/kbt26zXf3TqWnJ0OBvwK4yN2HhdvXAGcCVwDN3b3IzM4kVPC7R1tXp06dfN68eTFt98C3qu1foj279Thyl4wBoMMBLjlLyK1fS10mF5kXomdOllvVzp49m9zc3ETHiFmq5QVlrg6plhdSJHOUv3FJ+TcZSmSO599kMyuzwCd8iJ7Q0PwZZlbPzAw4D/gCmAX0Dc8zGHgzQflERERSTsILvLvPJTQk/19gAaFMzwC/Bkaa2TLgcOD5hIUUERFJMUlxFr27jwHGlJr8NXB6AuKIiIikvITvwYuIiEjVS4o9eBGRoIp2vTMkz0muEjzagxcREQkgFXgREZEAUoEXEREJIB2DF5GUoePZIrHTHryIiEgAqcCLiIgEkAq8iIhIAKnAi4iIBJAKvIiISACpwIuIiASQCryIiEgA6Tp4EUkuYxuVbLceB2N7h14ffWT154lFZObIvJC8mSXwtAcvIiISQCrwIiIiAaQCLyIiEkA6Bi9yCIt2b3fd132fVqPejtq/vE41BRGpAO3Bi4iIBFBMBd7MHjCzehHti82sbkS7oZm9FI+AIiIiUnGx7sH/GsiIaE8BWkS06wIDqiqUiIiIHJxYC7wdoC0iIiJJRMfgRUREAkgFXkREJIAqcpncCDMrjFhumJltDLcbVG0sERERORixFviVwLUR7bVA/zLmETlkRbumHHRduYhUr5gKvLu3inMOERERqUI6Bi8iIhJAsd7o5iQz61Zq2gAz+9rM1pnZBDOrFZ+IIiIiUlGxHoO/D/hfYBaAmbUFXgy3FwNDgdXAvXHIKJI8Uu2539GerQ7JmVlEqkSsQ/SnAn+LaF8NfOHu3d39FuBW4KoqziYiIiKVFGuBPxzIj2h3AaZHtGcD2hUQERFJErEW+PVADoCZpQEdgbkR/bWAPZUNYWaZZjbNzBab2SIzO9PMDjOz98zsy/B/G1d2/SIiIoeaWAv8bGCMmR0D3BaeNiuivy2w/CBy/B74H3dvA5wELAJGAR+4+3HAB+G2iIiIxCDWk+zuBt4HlgG7gZvdfVtE/yBCRbjCzKwRoSH/IQDuvhPYaWa9gdzwbJMIfcn4dWW2ISIicqgxd49tRrN0oB2w3t3zS/WdBKxy941lLhx9vScDzwBfENp7nw/cAqx298zwPAZ8t7ddavnhwHCArKysjlOmTIlpuwtWb47a36HGNyXahbWzydgR+md/USv6FYFtD28bU4YqtebTEs3IvBA9c0LylqGwsJCMjIwDz5hIEe9zRd5j0OciZlEyJ+o9rsjfi5T4XJSSar97kByfiwOq5N+Liubt1q3bfHfvVHp6zAU+XsysE/ARcLa7zzWz3wNbgJ9HFnQz+87dox6H79Spk8+bNy+m7bYa9XbU/uV1St6Jd3brceQuGQNAhwNcWpSQW5KWuhwqMi9Ez5wst1CdPXs2ubm5iY4RXcT7XJH3GPS5iFmUzIl6jyvy9yIlPhelpNrvHiTH5+KAKvn3oqJ5zazMAh/TEL2ZjYxlPnd/rEKpQlYR2vvfe9LeNELH2wvMrIW7rzGzFsC6SqxbRETkkBTrMfhHgA1AIWDlzONAhQu8u681szwza+3uS4DzCA3XfwEMBh4K//fNiq5bRETkUBVrgf+Y0PH3t4Hn3X1OFef4OfBq+Ha3XxN6cl0NYKqZDQNWAFdW8TZFREQCK9anyf3YzNoBw4C/mNl3wPPAJHcvONgQ7v4psN/xA0J78yIiIlJBMT9Nzt0/d/eRhG54cxehS9iWm9mbZlY7TvlERESkEmIdoi/m7ruAaWa2BagHXALUBXZUcTY5xHWY1KHcvmQ481hEqs6Br1SopiABUqHnwZtZKzO7x8xWAM8C/wKOc/dN8QgnIiIilRPrZXIDCD0S9kxCD5m5Hpjpib6IXqSKaS9CRIIi1iH6l4GVwBOELpdrC7QN3WBun0peBy8iIiJVLNYCv5LQde79osxTqevgReTQE22kRKMkIlUj1svkWh1oHjNredBpREREpEpU6CS7sphZczMbDyytgjwiIiJSBWIq8GaWaWavmtl6M8s3s5stZAyhO8+dQegkPBEREUkCsR6Df4DQM9snARcBjwMXAPWBHu7+j/jEExGR6qZ7UMQm2a+6ibXAXwJc6+7vm9kfgWXAV+5+a9ySiYiISKXFegw+m9DT3XD3r4EfCN3oRkRERJJQrAW+BrAror0b2F71cURERKQqxDpEb8ArZrb3fvN1gGfNrESRd/deVRlOREREKifWAj+pVPuVqg4iIiIiVSfWG91cG+8gcgga26hku/U4GNt7X/voI6s3j8ihQr97h4SDvtGNiIiIJB8VeBERkQBSgRcREQkgFXgREZEAUoEXEREJoFgvk5MkkIrP0E7FzCJBoN890R68iIhIAGkPXiTFaU9NRMqiPXgREZEAUoEXEREJIBV4ERGRAFKBFxERCSAVeBERkQBSgRcREQkgFXgREZEASpoCb2ZpZvaJmc0It482s7lmtszMXjOzWonOKCIikiqSpsADtwCLItq/BR5392OB74BhCUklIiKSgpKiwJvZEcAlwHPhtgHnAtPCs0wC+iQknIiISApKigIPPAHcDuwJtw8HNrl7Ubi9CshJQC4REZGUZO6e2ABmPYGL3f0GM8sFfgkMAT4KD89jZi2Bd929fRnLDweGA2RlZXWcMmVKTNtdsHpz1P4ONb4p0S6snU3GjnwAvqgV/XSAtoe3jSlDRUXLHC0vRM8cr7yQepkr8rmoSF7Q5yJSZTMn43sM+lxUhaD9TYbKfy4qmrdbt27z3b1T6enJUOAfBAYBRUAdoCHwV6A70Nzdi8zsTGCsu3ePtq5OnTr5vHnzYtputAd0ACyv079Ee3brceQuGQNAh6OPjLrsgsELYspQUdEfKlJ+XoieOV55IfUyV+RzUZG8oM9FpMpmTsb3GPS5qApB+5sMlf9cVDSvmZVZ4BM+RO/ud7j7Ee7eCrga+Lu7DwBmAX3Dsw0G3kxQRBERkZST8AIfxa+BkWa2jNAx+ecTnEdERCRlJNXz4N19NjA7/Ppr4PRE5hEREUlVybwHLyIiIpWkAi8iIhJAKvAiIiIBpAIvIiISQCrwIiIiAaQCLyIiEkAq8CIiIgGkAi8iIhJAKvAiIiIBlFR3shMRkZK2bNnCunXr2LVrV4WWe7ZXi3L7FtnUEu1GNTNZ1GrftCfSyy8NixYtqlCOWEXLC9EzR8sLyZH5YN7jmjVr0qxZMxo2bFihfCrwIiJJasuWLRQUFJCTk0PdunUxs5iX3bVqU7l9J9QouZ6ttbNpEPEo0z1RHmV6QpMTYs5QEdHyQvTM0fJCcmSu7Hvs7nz//fesXr0aoEJFXkP0IiJJat26deTk5FCvXr0KFXcJDjOjXr165OTksG7dugotqwIvIpKkdu3aRd26dRMdQ5JA3bp1K3yYRgVeRCSJac9doHKfAxV4ERGRAFKBFxGRpHDDoL689frkRMeokDen/onBl10U07xDbh3Db377hzgn2kdn0YuIpJBWo96Ow1r3nd29/Obs2LO0akVBQQFpaWnF05YuXUp2duzriPTHl6dVajkpm/bgRUSk0qZPn05hYWHxT2WLu1Q9FXgREalSrVq14v333y9ujx07loEDBwLwww8/MHDgQA4//HAyMzM57bTTKCgoAGDYFT35y+SXANizZw/P/P4RLjqjA7knH8c1N9/N5i1bAViel0/DJs2ZNHU6R552MZ1bd+bpx54uN8+QIUO44YYb6NGjBxkZGZx99tmsXbuWW2+9lcaNG9OmTRs++eST4vkXLVpEbm4umZmZtGvXjrfeequ4b+PGjfTq1YuGDRvSv+d55K34psS2vlm2lOv7X8o57Y+m9TmXMvWtvx3ku1l5KvAiIlJtJk2axObNm8nLy2Pjxo1MmDChzEsB35z6J956/U8899p03vn3JxRu385Nd/22xDxzPv6UJf/8C8/9+TkmPDqBr5Z+Ve52p06dyn333ceGDRuoXbs2Z555JqeeeiobNmygb9++jBw5EghdmviTn/yECy+8kHXr1vHkk08yYMAAlixZAsCNN95InTp1WLNmDeMeeZI3Xnu1eBvbt2/j+v6X0qN3X2Z9+iVTnnqQG+58iC+Wfl0Vb12FqcCLiEil9enTh8zMTDIzM+nTp88B569ZsyYbN25k2bJlpKWl0bFjxzLvzvbOG68z6LobOOKoVtSrn8GDo37OlLf+RlFRUfE8Y34xnLp169CmfRtat2vNks+XlLvdSy+9lI4dO1KnTh0uvfRS6tSpwzXXXENaWhpXXXVV8R78Rx99RGFhIaNGjaJWrVqce+659OzZk8mTJ7N7927+/Oc/c88991C/fn2Oa9OWXn2vLt7GP9+fSfYRR9LnqgGkp6dzSvs2XH7xubw+470KvKNVRyfZiYhIpb3xxhucf/75Mc8/aNAg8vLyuPrqq9m0aRMDBw7k/vvv32++9QVraXFEy+L2UUe0oKioiIL13xZPa97s8OLXderWYXvh9nK3m5WVVfy6bt26+7ULCwsByM/Pp2XLltSosW//96ijjmL16tWsX7+eoqIiWrbcl6vFES3hf0Ov16zOY8Gn8+nc7igAarCHoqLdDLr8kgO+L/GgAi8iIlWqfv36bN++r9iuXbu2+HXNmjUZM2YMY8aMYfny5Vx88cW0bt2a07pfXmIdTbOas2ZVXnF75eq1pKenk9X0MFatqdgtWysiOzubvLw89uzZU1zkV65cyfHHH0/Tpk1JT08nLy+PNm3ahP5tq1cVL9u8RQ6dzjibp//0VwBOrLHv+PzWuCUun4boRUSkSp188slMmTKFXbt2MW/ePKZN23f526xZs1iwYAG7d++mYcOG1KxZs8Te8l49el/OK889xaqVK9i+rZA7HxrPVb0uIP0AT447WD/+8Y+pV68eDz/8MLt27WL27NlMnz6dq6++mrS0NC677DLGjh3L9u3b+WrpYt6aNqV42S7nd2fF18uY/ufQv33Xrl18/OnnLPoyMcfgtQcvIpJClj8U23DvZ1GedBa5Zwn7P+nsYN17773069ePxo0b07VrV/r378+334aG1teuXcuIESNYtWoVGRkZXHXVVQwaNIgv1haWWEefqwayrmAtQ/tezM4dO7g493SevPfXVZaxPLVq1WL69OnccMMNPPjgg+Tk5PDSSy8V77GPHz+ea6+9lubNm3PkMcfR+8r+fPzhvwCon9GACa/+hUfuuYtH7/kNtqeIk9oex2Njbot77rKowIuISKUsX768zOnHHHMMc+fOLbOvX79+9OvXr8y+51+fUfy6Ro0ajLj1dkbcejtQ8ktJq5bZbNmwlvSILyUT35xYbs6JE0v2/fSnP+WnP/1pcfvYY48tcfJeu3bt+Mc//lHmupo2bcqMGaGcZX2JavWj4xg/aep+mbcCE58YV27GeNAQvYiISACpwIuIiASQCryIiEgAqcCLiIgEkAq8iIhIAKnAi4iIBFDCC7yZtTSzWWb2hZl9bma3hKcfZmbvmdmX4f82TnRWERGRVJHwAg8UAbe5e1vgDOBGM2sLjAI+cPfjgA/CbREREYlBwgu8u69x9/+GX28FFgE5QG9gUni2SUCfhAQUEZEKe/XVV7nwwgurZF3DrujJc+H7uyeTHmeeyEf/mn3A+fY+vz7yZjrVIanuZGdmrYBTgLlAlruvCXetBbLKW05E5JAxtlFMs51YgVU2iGwMnx3zcnPmzOH222/n888/Jy0tjRNOOIEnnniC0047jQEDBjBgwIAKpJCqZu6e6AwAmFkG8A/gfnf/i5ltcvfMiP7v3H2/4/BmNhwYDpCVldVxypQppWcp04LVm6P2dyh1r+bC2tlkhG+L+EWtWlGXbXt425gyVFS0zNHyQvTM8coLqZe5Ip+LiuQFfS4iVTZzMr7HEL/PRaNGjTj22GNLTGvw6BFR13ewtv58Kd/XsHL766bXBWDLli20a9eOxx57jMsuu4ydO3fyn//8h6ysLNq3b1/h7W7fubvcvkt79aT/FZcxeNC+Lwy7a9Qkbc8ugKh5IzNXtbbt2vHYE/+PLl1zy+yvxw4AVqxcSYdTT+fbtauKH5YTy3tc2rJly9i8ef/PYrdu3ea7e6fS05NiD97MagJ/Bl5197+EJxeYWQt3X2NmLYAynw/o7s8AzwB06tTJc3NzY9rmkFFvR+1fXmdMifbs1uPIXRKa9vOjj4y67ILLF8SUoaKiZY6WF6JnjldeSL3MFflcVCQv6HMRqbKZk/E9hvh9LhYtWkSDBg3K7Y+HBjvyWRnlS0m7xu0AWLJkCQBDhw4t7uvTp0/x64kTJ/Lcc88xZ84cAMyMp556ikcffZT169czYMAAxo8fj5mxe/dubrztFqZPm0y9jAyuGX4jD939a+Z/s5709HR27YE6RZuKH4jzwpQ3+O2Eyaxbt5bTT27HLx+/h+yW2ftlXb1yNd07dueFF15g9OjRFBYW8uCDD9KxY0eGDRvGypUrGThwIOPHjwdgz549PPDAAzz77LN8//33XHTRRTz55JM0ahQaNXn55Zf5zW9+Q2FhISNHjmSPw3c7oOD70LIvPvV7/vKnl9i6ZTM/7tyVyQ/dwmGNG5Gxc13xe5u+O1R2Y3mPS6tTpw6nnHJKucuVlvBj8GZmwPPAInd/LKLrLWBw+PVg4M3qziYiImU7/vjjSUtLY/Dgwbz77rt89913B1xmxowZfPzxx3z22WdMnTqVmTNnAvDss8/y79nvM3XmP3ntnX8wa+Y75a7jzZmzeeDJF3h10vOs/+wDzjn9VH51/a+ibnfu3Ll8+eWXvPbaa9x6663cf//9vP/++3z++edMnTq1+MEyEydOZOLEicyaNYuvv/6awsJCbrrpJgC++OILfvazn/Hyyy+Tn5/Pxo0bKVizb6Rm8ovPMGvmO7wwbQbvz1tEg0aNuPGuhw74nsRTwgs8cDYwCDjXzD4N/1wMPARcYGZfAueH2yIikgQaNmzInDlzMDOuu+46mjZtSq9evSgoKCh3mVGjRpGZmcmRRx5Jt27d+PTTTwGYOnUq/YdeT1aLHBpmZjL0hlvLXceEl6dxx01DaX388aSnp3PnzUNZsnAJ+XnlP+727rvvpk6dOlx44YXUr1+ffv360axZM3JycjjnnHP45JNPgNCJgSNHjuSYY44hIyODBx98kClTplBUVMS0adPo2bMnXbp0oXbt2tx7771YxHPsX3/lRX5++2/IapFDrdq1+dkvRjHt7Q+q/cS6SAkfonf3OUB5ByPOq84sIiISuxNOOKH4UayLFy9m4MCB3HrrrUyePLnM+Zs3b178ul69ehQWhp4Bn5+fT/PsnH3zRbwubcWqNdwy+nfcds8TwB4A3J2CNQVlDtMDZGXtO0e7bt26+7Ujcxx11FHFfUcddRRFRUUUFBSQn59Py5Yti/vq169PZuPDittrVuXxi+sGUSPi2HpaWg0K1n9b7r8l3hJe4EVEJPW1adOGIUOG8PTTT1d42RYtWpQY7l6bv7rceVtmZ3HXzcPo1e+nxcfkPz/AiYyxys7OZsWKFcXtlStXkp6eTlZWFi1atGDRokXFfdu3b2fTd/uKd1Z2DuMeeZJTTjujeNre58EvjzK6EE/JMEQvIiIpZvHixTz66KOsWrUKgLy8PCZPnswZZ5xxgCX3d+WVV/LqC09TsCafLZs38+JTvy933hGD+vLg+BdZtHgxAJu3bGXmmzMr948opV+/fjz++ON88803FBYWcuedd3LVVVeRnp5O3759mTFjBnPmzGHnzp2MHj0a37OneNkrBl7L+IfvI3/VSgC+3biBN2fOrpJclaU9eBGRVDI2+iV7e322alO5fSeWuhRxa+3s4r3hWDVo0IC5c+fy2GOPsWnTJjIzM+nZsye/+93vKrQegOuuu47/zF/AFRd2pn6DBvS/9nrmfTiHtLS0/ea9tMe5FG7bzrXXjSAvL49GDTLolHsm3Xt3r/B2Sxs6dCj5+fl06dKFH374ge7du/Pkk08C0K5dO/7whz/Qv39/tm3bxsiRI8lqse+QwIBhI3B3Rgy4nPUFazns8CYM6tWN3t1zDzpXZanAi4hIheXk5DB16tRy+4cMGcKQIUOK26XvubL32D1Aeno6vxr7AL8a+wAAc2a9R9Os5oQusoLnX59R4kvJoL496TNg+AGH6HOOzGHh+oXF154DxSMOe73yyivFr2vUqMHo0aMZPXp0mesbPHgwgwcPLm7/ZPCNJZa9ZviNXDN837S9mVu1zGbLhrWkV/BL1MHSEL2IiCTU999/z7/+/rfQCW1r8pnw+MOce1HPRMdKeSrwIiKSUO7OU48+xDntj+aqHl05+tjjueG2OxIdK+VpiF5ERBKqXr16/Ontvyc6RuBoD15ERCSAVOBFREQCSAVeREQkgFTgRUREAkgFXkREJIBU4EVEpMplZGTw9ddfH/R67v7FDYx/+D4A/jX3v7Q+59KDXmd1y+17HZNefjWmeds3bc+yZcuqZLu6TE5EJIV0mNQhrutfcMFLMc/bqlUrCgoKSEtLo379+vTo0YPx48eTkZFR/IS2qnTOj09lyb/+WuXrDSrtwYuISKVNnz6dwsJC/vvf/zJv3jzuu+++REeSMBV4ERE5aDk5OfTo0YOFCxcCYGbFQ81DhgxhxIgRXHDBBTRo0ICuXbuWeCzr4sWLub7/pZzT/mh6dT2NmdPL3kuf/Z95HNHxouJ2qx9fwiMTXuLSrpdyxjFncNtPb2PHDzv2zf+32VyeezmZmZmcddZZfPbZZ+XmNzP++Mc/ctxxx9GgQQPuvvtuvvrqK8466ywaNmzIlVdeyc6dO4vnf/bZZ+nZ+VTOaX80N1/bj3Vr1xT3ffjPWfTOPZ1Gbbpw010P7Xcf/hemvMFPzvoJZx17FsOvGE5+nB4nqwIvIiIHLS8vj3feeYdTTjmlzP5XX32Vu+++mw0bNnDyySczYMAAALZt28YFF1xAj959mfXpl/z2D8/zwF2/5Kuli2Pa7tTp7/H0a08zc/5Mln6xlDemvAHAos8WMfqW0Yx5dAwbN27k+uuvp1evXuzYsaPcdc2cOZP58+fz0Ucf8fDDDzN8+HBeeeUV8vLyWLhwIZMnTwbg73//O3fccQe/e+pFPpi/mBZHtOTXNw4D4LtvNzJy+DXc9Ku72LDgA3501BH8++P/K97GmzNn88CTL/DExCf45+J/0vGMjvzq+l/F9G+tKBV4ERGptD59+pCZmUnnzp3p2rUrd955Z5nzXXLJJXTp0oXatWtz//338+GHH5KXl8eMGTNo1aoVfa4aQHp6Oie0P5HzLv4J7739Zkzbv3no1TRr3oxGjRuR2z2XxQtDXwxef/l1rrjmCk7seCJpaWkMHjyY2rVr89FHH5W7rttvv52GDRvSrl072rdvz4UXXsgxxxxDo0aN6NGjB5988gkQ+rIydOhQTuhwErVq1+aWUaP57L8fszpvJXP+/h4/Or4NF1zSm5o1a3LrdQNo3vTw4m1MeHkad9w0lB8d/yPS09O57hfXsWThkrjsxeskOxERqbQ33niD888//4DztWzZsvh1RkYGhx12GPn5+axYsYK5c+fSud1Rxf1FRbvpedmVMW2/edMmxa/r1K3DurXrAFiTt4a3XnuLPz33J2pYaF92586d5OeXX0izsrKKX9etW3e/9tq1awHIz8/n1FNPLe6rVz+DRo0PY93afNYVrKF5dk5xn5nRMnvfelasWsMto39HjXseL57m7hSsKSC75b7ny1cFFXgREYm7vLy84teFhYV8++23ZGdn07JlS7p27cqjL75epdtrntOc6269jutHXk+7Ju2qdN3Z2dmsWLGCc8Lt7du3sfm7b2nWPJumzZozK/+d4nndnbz8guJ2y+ws7rp5GCdf3adKM5VFQ/QiIhJ377zzDnPmzGHnzp3cfffdnHHGGbRs2ZKePXuydOlSpv95Crt27WLXrl0s/PS/fP3lkoPa3uWDLmfqpKl8Nv8z3J1t27bx9ttvs3Xr1oP+t/Tr148XX3yRxZ8vYOeOHTz523tpf0pHcloeyTnnXchXSxfz/rvTKSoq4v89P5m16zcWLztiUF8eHP8iyxaHTkDcumUrM9+cedCZyqI9eBGRFLJg8IKY5vts1aZy+06s8U2J9tba2TTYEZ8zuffq378/48aN48MPP+TUU0/llVdeAaBBgwb87W9/47obfs6j9/yGPXv2cHzb9vxy9P0Htb32J7dn3GPjuH/U/fzsqp9Rt25dOnfuTJcuXQ7633L++edz7733ctvwa9iyeRMndTqdh//wPACNDzucR556kYfGjGLcbQUMuvxizj7tpOJlL+1xLoXbtvOr4b8iPy+fjIYZnNn1TLr37n7QuUpTgRcRkUpZvnx5uX2lLw1r0qQJEyZMKHPe1q1bM37S1DL77n38j+FX35B7VidWzf+ffduf+zYAn4fbN95+Y4llO5/Xmc7ndY5piL503jlz5pRol76+f8SIEZzV8+oy13V2t/OZ3m1eiS9SW2tnQ/hL1KC+PTm1/2VlLrtw/UKObXLsAfPGQkP0IiIiAaQCLyIiEkAaohcRkbiaOHFioiMckrQHLyIiEkAq8CIiSWzPnj2JjiBJoDKfAxV4EZEkVb9+fVavXs3OnTv3O8tbDg3uzs6dO1m9ejX169ev0LI6Bi8ikqSOOOIINmzYwIoVKygqKqrQsgXffV9u3yJbX6L9Q82d1Nm1qbi9Nr380lBjfXz2C6PlheiZo+WF5Mh8MO9xeno6jRo1okmTJuUsUTYVeBGRJFWjRg2aNWtGs2bNKrxsj1Fvl9u3vE7/Eu3ZrcdxypIxxe0rjz6y3GVjvdFORUXLC9EzR8sLyZE5Ee9x0g/Rm9lFZrbEzJaZ2ahE5xEREUkFSV3gzSwN+APQA2gL9DOztolNJSIikvySusADpwPL3P1rd98JTAF6JziTiIhI0kv2Ap8D5EW0V4WniYiISBSWzJdemFlf4CJ3/2m4PQj4sbvfFDHPcGB4uNkaOLhnDJavCbAhTuuOh1TLC6mXOdXygjJXh1TLC8pcHeKZ9yh3b1p6YrKfRb8aaBnRPiI8rZi7PwM8E+8gZjbP3TvFeztVJdXyQuplTrW8oMzVIdXygjJXh0TkTfYh+o+B48zsaDOrBVwNvJXgTCIiIkkvqffg3b3IzG4CZgJpwAvu/vkBFhMRETnkJXWBB3D3d4B3Ep2DajgMUMVSLS+kXuZUywvKXB1SLS8oc3Wo9rxJfZKdiIiIVE6yH4MXERGRSlCBFxERCSAVeBERkQBK+pPsEsHMTgAGAe2ABsBW4HPgZXdflMhsQWFmRwIdgc/dfWmpvn7uPjkxycpnZqcAPyJ00ucO4Gfh9vvuHv2xUknCzOYBF7r7t4nOciBmdjRwMWDA/7j7sgRH2o+ZnQ187e5rzKw28BtCmQGmAw+Eb7MtlWRmNYAbCP09ftfd3zKz3xJ6Rsn/ASPdfX20dSSCmR1LqI60B+oRuhPr/wIT3X1XtWTQSXYlmVk/4ClC19v/H7AZaAicBPQCRrj7a4lLWDHhB/bc5e73JDrLXmZ2ETAV+AY4DpgI/Nzdd4f7t7h7w8Ql3J+ZDQPuAxzIB/5C6CZM6YTuz3CLu7+QuIQlmdlL5XT1BWYAP7j7NdUY6YDMbJG7nxB+3ZVQgfw3off8HKC3u/89gRH3Y2ZfAl3CBf5J4BTgMUKZfwHMd/dfJDJjJDP7PTDV3f+d6CyxCr+vXYH/IVTUPwYOA14EBgM73f3qxCXcn5n1AV4h9Pk1QvlfI7RD0By4wN2/jnsOFfiSzOwbYGBZvwDhb+uvunurag9WSeG9iu3unpboLHuZ2X+Bu939bTPLIvSLsAO4zN13mtlWd2+Q2JQlmdliQl/wDFgEdHb3/4T7ugMPu/tJCYxYgpl9T2hv4QNCmff6JTABKHT3cYnIVp7I/+9m9i/gWXd/KdweANzo7mclMmNpZlbo7hnh1yuBk/eOjphZY0IjVNmJzBjJzIqA7cA64CVgkruvSGyq6Mwsn9D7us7McoCVQBN3/87MMoGl7t4soSFLMbOlwPXuPivcvhD4hbv3MLNfAt3c/ZK451CBL8nMCoGm7v59GX31gHV7f6GThZlF23NMBwYkWYHf7O6NItrphIp8E0JFtCAJC3xxZjPbBmR4+JcnPIT4rbtnJjBiCWZ2HDAe+I7QEGZ+ePoa4CR3X5fIfGWJHLkxs3VAzt6hzPBI1Hp3PyyRGUszsy+Awe7+cXhv/uy9762ZNSVUfBonNGQEM9tKaA+yL3AN0AWYQ2gUbZq7b0tcurKZ2bdAlrvvMrO6wBagXridrJ+LTUDjiL8R6cAad28ariNrq2OUUifZ7e894AUz+1HkxHD72XB/sukPfE/oPv2lf1YlMFd5vjOz4mcMuHsR0I/QN/P3Cd21MNlsM7Oa4dcTveQ347rAngRkKpe7f+nu3YE3gFlm9svwH5lk/kZf08yuNbOhhHLWiuhLJzk/F/cAU83sWuA5YIaZDTSzgYQOhfwpoen25+6+zd0nuft5wLGERnnuBNaa2cSEpivbh8DT4UN7EwgdOr3NzBoAt4XbyWY+cHNE+1ZC53EB7AaKqiWFu+sn4gdoDEwmNGRcSOh4ayHwA6Ff1saJzlhG5o+BXuX01QH2JDpjqUzPAaPL6ZuQbHnDuV4GTiin7ypgdqIzRsneEHgCWEjohNFmic5UTs7ZwKyIn9Mi+i4E/jfRGcvJfQGhY607CH3R20Poy+o4ID3R+Upl3RKl7yxgQqIzlpHrKOBtQgXyOqANsJxQoVwGnJjojGVkbkPoyaZbwj/LgPbhvg6EDunFPYeG6MsRHkY5HsggVOCXuvv2xKYqm5ndCKx29zfK6EsDfuNJdLw1/OCg9PLeTzM70t1XVnOsSgsPxbq7J/WjK83sZEIn+zzt7j8kOE6FmFkjoGYyv8fhQzVZwPfuvinBccqUjOe3VIaZGXCYu29MdJbyhP/2tgk3l3hopLJ6M6jAi4iIBI+OwYuIiASQCryIiEgAqcCLSFRmNtHMZhxgnhnRzsA2syFm5uGfCRHTZ5vZ+CjLjY1Y7peV+geIHKJU4EUCLlygvYyfk6s5ynagBXB7BZZ5JLxMMl7uKZLUdC96kUPD+4Tuix2pus9Id3dfW8EFCoFCM9sdp0wigaU9eJFDww53X1vqpwjAzLqY2Vwz+8HMCszs8fCljGUys3rhUYHC8Px3VlVIMzvPzDaZ2YiqWqfIoUoFXuQQFr6397vAJ4QelDKM0F0FH4yy2COEbu5yOXBeeLkuVZClL/BXYLi7TzjQ/CISnQq8yKHhovAe996fd8PTbyB0t8Yb3H2Ru88ARgE3hW/2VIKZZRD6EnC7u89094XAtRzkrXrNbDjwPNDX3acezLpEJETH4EUODf8Ehke09z5M6QTgI3ePLNBzCN0H/ljgs1Lr+VG478O9E9y90MwWHES2PsD1hB67+uEB5hWRGKnAixwatrv7sgouU123ufw/QvfnHmZmH7lurylSJTREL3JoWwScEb6P+l6dgZ3AV2XM/xWwCzhj7wQzqw+0P4gM3wC5hB4o80z4PuMicpBU4EUObX8EsoE/mtkJZnYJ8BAwvqyHAYUvW3se+K2ZXWBm7YAXOMhHubr710A34CJCjwZVkRc5SBqiFzmEuftqM+sB/A74FNhE6LHI0S59+yVQn9AZ79uBJ8Ptg83ylZnlEnps7NNmdr2G60UqT0+TE5G4M7MhhEYFMiq5/PLw8o9UZS6RINMQvYhUl/rhS/SeiHUBM7vTzAqBI+MXSySYtAcvInFnZg2ArHBzs7uvj3G5w4DDws0N7r4pDvFEAkkFXkREJIA0RC8iIhJAKvAiIiIBpAIvIiISQCrwIiIiAaQCLyIiEkAq8CIiIgH0/wG9FP7yslQ27AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = pd.read_csv('SF_fusion2.csv')\n",
    "dt = dt.rename({'RMSEfusion':'Fusion model','RMSEreg':'Single model','RMSEpipe':'Pipeline model'},axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "dt.plot.bar(figsize=(8,4.5))\n",
    "plt.ylabel('RMSE',fontsize=14)\n",
    "plt.xlabel('Fold [k]',fontsize=14)\n",
    "plt.legend(fontsize=12,loc='lower right')\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(10),np.arange(10),fontsize=12)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0364552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3be8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c22de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b9199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef96599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a7e518",
   "metadata": {},
   "source": [
    "More advanced hyper-parameter optimization (using evolutionary algorithm, TPOT package), not included in the paper (results are similar to random search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b84d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.28362255070780235\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.28362255070780235\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.28362255070780235\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.28362255070780235\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.28362255070780235\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.99, learning_rate=0.1, loss=lad, max_depth=9, max_features=0.6000000000000001, min_samples_leaf=12, min_samples_split=17, n_estimators=100, subsample=0.6000000000000001)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10,template='Regressor',population_size=50, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestfullreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63701c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.015318264676631676\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.014913248709005792\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.014629825111804806\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.014629825111804806\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.014629825111804806\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.99, learning_rate=0.1, loss=lad, max_depth=9, max_features=0.45, min_samples_leaf=12, min_samples_split=17, n_estimators=100, subsample=0.6000000000000001)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[0,40],dataset='sf')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10, template='Regressor',population_size=50, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestAreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f82fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.2023757211233609\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.2023757211233609\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.20031564276479408\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.19457925256068012\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.1942929066981764\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=4, min_child_weight=8, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.25, verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "X,Y = getBFS(part=[40,-1],dataset='sf')\n",
    "X = X.values\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, cv=10, template='Regressor',population_size=50, verbosity=2, n_jobs=30,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "tpot.fit(X,np.log1p(Y))\n",
    "# print(tpot.score(X,Y))\n",
    "bestBreg = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a17d79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7203215476650155\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7203215476650155\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7203215476650155\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7203215476650155\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7203215476650155\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.001, max_depth=8, max_features=0.05, min_samples_leaf=12, min_samples_split=9, n_estimators=100, subsample=0.55)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "X = X.values\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=40).ravel()\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, cv=10, scoring='f1', template='Classifier',population_size=50, verbosity=2, n_jobs=30,random_state=42,config_dict=tpotcla_config)\n",
    "tpot.fit(X,Ybin)\n",
    "# print(tpot.score(X,Ybin))\n",
    "bestfullcla = tpot.fitted_pipeline_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1b3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEfull,RMSEreg\n",
      "52.0,100.0\n",
      "109.0,135.0\n",
      "56.0,110.0\n",
      "45.0,60.0\n",
      "44.0,49.0\n",
      "45.0,46.0\n",
      "51.0,56.0\n",
      "59.0,59.0\n",
      "45.0,52.0\n",
      "80.0,95.0\n",
      "RMSEfull,RMSEreg\n",
      "52.0,100.0\n",
      "109.0,135.0\n",
      "56.0,110.0\n",
      "45.0,60.0\n",
      "44.0,49.0\n",
      "45.0,46.0\n",
      "51.0,56.0\n",
      "59.0,59.0\n",
      "45.0,52.0\n",
      "80.0,95.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "X,Y = getBFS(part=[0,-1],dataset='sf')\n",
    "X = X.values\n",
    "\n",
    "# def quantilefold(X,Y):\n",
    "#     zipped = list(zip(X,Y))\n",
    "#     X = [A for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     Y = [B for A,B in sorted(zipped, key = lambda x: x[1])]\n",
    "#     X = np.array(X)\n",
    "#     Y = np.array(Y)\n",
    "#     return X,Y\n",
    "\n",
    "# X,Y = quantilefold(X,Y)\n",
    "\n",
    "\n",
    "Ybin = binarize(Y.reshape(-1,1),threshold=40).ravel()\n",
    "Yfull = np.concatenate([Y.reshape(-1,1),Ybin.reshape(-1,1)],axis=1)\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "kf.get_n_splits(X,Yfull)\n",
    "\n",
    "print(\"RMSEfull,RMSEreg\")\n",
    "\n",
    "RES=[]\n",
    "\n",
    "for train_index, test_index in kf.split(X,Yfull):\n",
    "    \n",
    "    # reset models (since some may use iterative training)\n",
    "#     bestAreg.fit([[0],[0]],[0,0])\n",
    "#     bestBreg.fit([[0],[0]],[0,0])\n",
    "#     bestfullreg.fit([[0],[0]],[0,0])\n",
    "#     bestfullcla.fit([[0],[0]],[0,1])\n",
    "#     print()\n",
    "    \n",
    "    Xtr, Xte = X[train_index], X[test_index]\n",
    "    Ytr, Yte = Yfull[train_index], Yfull[test_index]\n",
    "    \n",
    "    # one regression model predictions\n",
    "    reg = bestfullreg\n",
    "    reg.fit(Xtr,np.log1p(Ytr[:,0]))\n",
    "    Rpreds = np.expm1(reg.predict(Xte))\n",
    "    RTrpreds = np.expm1(reg.predict(Xtr))\n",
    "    \n",
    "    #one classification model predictions\n",
    "    cla = bestfullcla\n",
    "    cla.fit(Xtr,Ytr[:,1])\n",
    "    Cpreds = cla.predict(Xte)\n",
    "    CTrpreds = cla.predict(Xtr)\n",
    "    \n",
    "    \n",
    "    # A- and B- models try to predict\n",
    "    regA = bestAreg\n",
    "    regB = bestBreg\n",
    "    \n",
    "    As = Ytr[:,1]==0\n",
    "    Bs = Ytr[:,1]==1\n",
    "    regA.fit(Xtr[As],np.log1p(Ytr[As,0]))\n",
    "    regB.fit(Xtr[Bs],np.log1p(Ytr[Bs,0]))\n",
    "    \n",
    "    Apreds = np.expm1(regA.predict(Xte))\n",
    "    Bpreds = np.expm1(regB.predict(Xte))\n",
    "    \n",
    "    ATrpreds = np.expm1(regA.predict(Xtr))\n",
    "    BTrpreds = np.expm1(regB.predict(Xtr))\n",
    "    #accumulating predictions\n",
    "    \n",
    "    R3tr = np.concatenate([reg.predict(Xtr).reshape(-1,1), regA.predict(Xtr).reshape(-1,1), regB.predict(Xtr).reshape(-1,1), cla.predict(Xtr).reshape(-1,1)],axis=1)\n",
    "    R3te = np.concatenate([reg.predict(Xte).reshape(-1,1), regA.predict(Xte).reshape(-1,1), regB.predict(Xte).reshape(-1,1), cla.predict(Xte).reshape(-1,1)],axis=1)\n",
    "#     print(R3tr.shape,Ytr[:,0].shape)\n",
    "\n",
    "    from sklearn.linear_model import RidgeCV\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "    full = XGBRegressor()#DTR(max_depth=4)\n",
    "#     full = TPOTRegressor(generations=5, template='Regressor',population_size=40, verbosity=2, n_jobs=20,random_state=42, scoring='neg_mean_squared_error',config_dict=tpotreg_config)\n",
    "    full.fit(R3tr,np.log1p(Ytr[:,0]))\n",
    "#     bestfullreg.fit([[0],[0]],[0,0])\n",
    "#     finalreg = bestfullreg\n",
    "#     finalreg.fit(R3tr,Ytr[:,0])\n",
    "    \n",
    "    \n",
    "    PREDS = np.expm1(full.predict(R3te))\n",
    "    \n",
    "    \n",
    "    \n",
    "    TRPREDS = []\n",
    "    \n",
    "    for i in range(len(Xtr)):\n",
    "        \n",
    "        if CTrpreds[i]==0:\n",
    "            TRPREDS.append(ATrpreds[i])\n",
    "            \n",
    "        if CTrpreds[i]==1:\n",
    "            TRPREDS.append(BTrpreds[i])\n",
    "            \n",
    "    TEPREDS = []\n",
    "    \n",
    "    for i in range(len(Xte)):\n",
    "        \n",
    "        if Cpreds[i]==0:\n",
    "            TEPREDS.append(Apreds[i])\n",
    "            \n",
    "        if Cpreds[i]==1:\n",
    "            TEPREDS.append(Bpreds[i])  \n",
    "    TRPREDS = np.array(TRPREDS).reshape(-1,1)  \n",
    "    \n",
    "#     print(TRPREDS.shape)\n",
    "    TEPREDS = np.array(TEPREDS).reshape(-1,1)\n",
    "#     print(TEPREDS.shape)\n",
    "    \n",
    "    full.fit(np.concatenate([RTrpreds.reshape(-1,1),CTrpreds.reshape(-1,1),ATrpreds.reshape(-1,1),BTrpreds.reshape(-1,1)],axis=1), np.log1p(Ytr[:,0]))\n",
    "    PREDS = full.predict(np.concatenate([Rpreds.reshape(-1,1),Cpreds.reshape(-1,1),Apreds.reshape(-1,1),Bpreds.reshape(-1,1)],axis=1))\n",
    "    PREDS = np.expm1(PREDS)\n",
    "#     PREDS=PREDS\n",
    "    \n",
    "    rA, rB = np.sqrt(mse(Yte[:,0],np.array(PREDS))), np.sqrt(mse(Yte[:,0],np.array(Rpreds)))\n",
    "\n",
    "    rA = np.round(rA)\n",
    "    rB = np.round(rB)\n",
    "\n",
    "    print(\"{},{}\".format(rA, rB))\n",
    "    RES.append(\"{},{}\".format(rA, rB))\n",
    "#     print(PREDS[0],Rpreds[0])\n",
    "\n",
    "\n",
    "print(\"RMSEfull,RMSEreg\")\n",
    "print(\"\\n\".join(RES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde5f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
